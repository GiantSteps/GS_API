{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS-API examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not installed gsapi python module yet, follow the instructions:\n",
    "\n",
    "Download : https://github.com/GiantSteps/GS_API\n",
    "\n",
    "Open terminal:\n",
    "- cd GS_API/python\n",
    "- python setup.py build\n",
    "- python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the GS API module\n",
    "from gsapi import GSPattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All submodules within API provide help by typing help(Name of the module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(GSPattern)\n",
    "#help(GSBassmineAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drum and bass generative example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drums example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gsapi import *\n",
    "\n",
    "#Select the folder where the MIDI files for analysis are located\n",
    "\n",
    "defaultMidiFolder = \"../../test/midiDatasets\"\n",
    "\n",
    "#Use 'GSDataset' to extract the MIDI file\n",
    "\n",
    "dataset = GSDataset(midiFolder=defaultMidiFolder,midiGlob=\"motown.mid\",midiMap=GSIO.generalMidiMap,checkForOverlapped = True)\n",
    "\n",
    "#use the function'splitInEqualLengthPatterns' to split the \n",
    "#contents of the dataset and to set the minimum \"grain\" or \"timeframe\" of the analysis\n",
    "#save each slice as an element in a list called \"allPatternsSliced\"\n",
    "\n",
    "allPatternsSliced = []\n",
    "sizeOfSlice = 16\n",
    "for midiPattern in dataset.patterns:\n",
    "    for sliced in midiPattern.splitInEqualLengthPatterns(sizeOfSlice):\n",
    "        allPatternsSliced+=[sliced]\n",
    "\n",
    "#set the parameters of the markov style: the order, the number of steps and the final duration of the output\n",
    "#and create an instance of GSMarkovStyle called \"markovstyle\"\n",
    "\n",
    "markovStyle = GSMarkovStyle(order=1,numSteps=16,loopDuration=sizeOfSlice);\n",
    "\n",
    "#generate a style based on the sliced patterns in the list \"allPatternsSliced\"\n",
    "markovStyle.generateStyle(allPatternsSliced)\n",
    "\n",
    "#Create a pattern simply using the function \"generatePattern\" of the markovStyle\n",
    "newPattern = markovStyle.generatePattern()\n",
    "\n",
    "# Export to MIDI\n",
    "newPattern.toMIDI(name=\"drums\", midiMap=MidiMap.generalMidiMap)\n",
    "\n",
    "#print the pattern for visualization\n",
    "print newPattern\n",
    "\n",
    "#Extract the only the pattern of the kick drum from the complete pattern.\n",
    "#Using the function \"getPatternWithTags\" and asking for the 'Acoustic Bass Drum' tag\n",
    "#makes it easy. To create such list, we should first extract the events as a class called \"justkick\"\n",
    "#and then extract each event on the class using justkick.events.\n",
    "\n",
    "\n",
    "justkick=newPattern.getPatternWithTags('Acoustic Bass Drum', exactSearch=True, copy=True)\n",
    "\n",
    "kickAsList=[0]*sizeOfSlice\n",
    "for s,e in enumerate(justkick.events):\n",
    "\n",
    "    kickAsList[int(e.startTime)]=1\n",
    "\n",
    "print kickAsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bassmine example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following script commands present examples of Bassline rhythmic analysis for generative processes using GS-API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gsapi.GSBassmineAnalysis as bassmine\n",
    "import gsapi.GSBassmineMarkov as markov\n",
    "import json\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to determine the datasets to use. In this case we need to provide a dataset that contains MIDI clips of basslines and drums in pairs. That means that each bass MIDI file has an associated drum MIDI file. \n",
    "\n",
    "The implemented algorithm builds two Markov models.\n",
    "\n",
    "First, contains the transition probabilities between bass beat patterns (temporal)\n",
    "Second, contains the concurrency probabilities between kick-drum and bass beat patterns.\n",
    "Moreover, the initial probabilites of events are computed, used to trigger the generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STYLE DICTIONARY\n",
    "style = {1: 'booka_shade', 2: 'mr_scruff'}\n",
    "\n",
    "# SELECT STYLE\n",
    "style_id = 2\n",
    "\n",
    "bass_path = '../../corpus/bassmine/' + style[style_id] + '/bass'\n",
    "drum_path = '../../corpus/bassmine/' + style[style_id] + '/drums'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implemented algorithm in [bassmine.corpus_analysis] builds two Markov models.\n",
    "\n",
    "- Transition probabilities between bass beat patterns (temporal). \n",
    "- Concurrency probabilities between kick-drum and bass beat patterns (interlocking). \n",
    "\n",
    "Moreover, the initial probabilites of events are computed, used to trigger the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyse corpus and build Markov model\n",
    "MM, kick_patterns = bassmine.corpus_analysis(bass_path, drum_path)\n",
    "# Normalize transition matrices\n",
    "MM.normalize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once models are computed we can export them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output folder (to use with Max this folder should be Bassmine-master/models/)\n",
    "_path = 'output/'\n",
    "#  Uncomment to create models and export to pickle. REQUIRED to add new collections and use them in Max app.\n",
    "# Export to pickle files\n",
    "bassmine.write2pickle('initial', MM.get_initial(),_path + style[style_id] + '/')\n",
    "bassmine.write2pickle('temporal', MM.get_temporal(),_path + style[style_id] + '/')\n",
    "bassmine.write2pickle('interlocking', MM.get_interlocking(),_path + style[style_id] + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stylistic transformations using Markov Models with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute Rhythm Homogeneous MM (HMM) and export to JSON\n",
    "HModel = MM.rhythm_model(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a Kick pattern generate a NHMM with interlocking constraint\n",
    "# Select a random Kick pattern from the corpus\n",
    "target_kick = kick_patterns[random.randint(0,len(kick_patterns)-1)]\n",
    "#print target_kick\n",
    "#target = [8,8,8,9,8,8,9,0]\n",
    "NHMinter = markov.constrainMM(MM, target_kick, _path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create variation model\n",
    "target_bass = [5,5,-5,5,5,-5,5,5]\n",
    "NHMvariation = markov.variationMM(MM, target_bass, _path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example od generation without constraints. It computes Homogeneous Markov Model (HM)\n",
    "pattern = markov.generateBassRhythm(MM)\n",
    "pattern.toMIDI(name='regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of generation using Interlocking constraint.\n",
    "inter_pattern = markov.generateBassRhythm(MM, target=target_kick)\n",
    "# Write pattern to MIDI\n",
    "inter_pattern.toMIDI(name='interlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of variation generation\n",
    "var_mask = [1, 1, 1, -1, 1, 1, -1, 1]\n",
    "variation_pattern = markov.generateBassRhythmVariation(MM,inter_pattern,var_mask)\n",
    "variation_pattern.toMIDI(name='variation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
